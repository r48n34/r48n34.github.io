<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>CNN model imports</title>
    </head>
    <body>
        <script is:inline src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>

        <input
            type="file"
            id="avatar"
            name="avatar"
            accept="image/png, image/jpeg"
        />
        <img id="img" style="width:600px; height:auto; max-width: 1200px;" />

        <script is:inline>
            const img = document.getElementById("img");
            const avatar = document.getElementById("avatar");

            let myModel;

            window.onload = async () => {
                await tf.ENV.set("WEBGL_PACK_DEPTHWISECONV", "false");
                loadModel();
            };

            async function loadModel() {
                console.log("Loading Models");

                const start = new Date();
                // #tensorflowjs_converter --input_format=keras --output_format=tfjs_graph_model <input_path> <output_path>
                myModel = await tf.loadGraphModel(
                    "https://cdn.jsdelivr.net/gh/r48n34/self-tf-Model-storage/5Classv3Graph/model.json"
                );

                console.log(
                    "Time used to init: ",
                    (new Date() - start) / 1000,
                    " Done"
                );

                // const resource = await tf.util.fetch(
                //     "https://firebasestorage.googleapis.com/v0/b/fypserver-160d2.appspot.com/o/istockphoto-1053854126-170667a.jpg?alt=media&token=e089b111-fc91-45b9-8252-52e7aae03597"
                // );

                // console.log(resource);
            }

            //https://firebasestorage.googleapis.com/v0/b/fypserver-160d2.appspot.com/o/istockphoto-1053854126-170667a.jpg?alt=media&token=e089b111-fc91-45b9-8252-52e7aae03597

            let res;

            async function useModel() {
                let start = new Date();

                // Read img and reshape it
                // https://stackoverflow.com/questions/54774073/incorrect-predictions-when-using-the-keras-pre-trained-inceptionv3-xception-mode
                // normalizing the images into the range [-1, 1] before inputting them !!
                let imgPre = await tf.browser
                    .fromPixels(img)
                    .resizeNearestNeighbor([224, 224])
                    .toFloat()
                    .sub(tf.scalar(0)) // may set to 0 or just remove it
                    .div(tf.scalar(1)) // may set to 1 or just remove it
                    .expandDims();

                let afterResize = new Date();
                console.log(
                    "Img resize & rescale time",
                    (new Date() - start) / 1000
                );
                console.log(imgPre);

                // predict the inupt and output softmax prob
                const p = await myModel.predict(imgPre).data();

                // Get result and print regarding label
                const labelMyModel = ["bird", "cat", "dog", "fish", "lion"];
                let ind = p.indexOf(Math.max(...p));
                console.log(p);

                console.log("MyModel:", labelMyModel[ind]);

                console.log(
                    "Time used to predict: ",
                    (new Date() - afterResize) / 1000
                );
                console.log("Overall time: ", (new Date() - start) / 1000);
                console.log("----------------------------");
            }

            avatar.addEventListener("input", async (e) => {
                let f = e.currentTarget;
                const files = f.files[0]; // get files

                if (files) {
                    const fileReader = new FileReader();
                    fileReader.readAsDataURL(files);

                    fileReader.addEventListener("load", async function () {
                        img.src = this.result;
                        await timer(200);
                        useModel();
                    });
                }
            });

            function timer(t) {
                return new Promise((rec) => {
                    setTimeout(rec, t);
                });
            }

            /*
  in .py
  tfjs.converters.save_keras_model(model, "./normalNoTop3CoffeeTea")
  // tfjs does not support the resize / rescaling!!!!
  // Don't train your model with img_args and resize in your model
  // Outside OK
  (Not OK)
  resize_and_rescale = tf.keras.Sequential([
    layers.experimental.preprocessing.Resizing(imgSize, imgSize),
    layers.experimental.preprocessing.Rescaling(1./imgSize)
  ])
  data_augmentation = keras.Sequential([
    layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
    layers.experimental.preprocessing.RandomRotation(0.1),
    layers.experimental.preprocessing.RandomZoom(0.1),
  ])
  model = Sequential([
    resize_and_rescale,
    data_augmentation,
    baseModel,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(classNum, activation=tf.nn.softmax)
  ])
  (OK)
  valid_ds = valid_ds.map(lambda image,label:(resize_and_rescale(image),label))
  valid_ds = valid_ds.map(lambda image,label:(data_augmentation(image),label))
  train_ds = train_ds.map(lambda image,label:(resize_and_rescale(image),label))
  model = Sequential([
    baseModel,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(classNum, activation=tf.nn.softmax)
  ])
  
  */

            //tensorflowjs_converter --input_format=keras F:\fileHa2 F:\yos
        </script>
    </body>
</html>
